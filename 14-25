import requests
import numpy as np
import cv2
import easyocr

ESP32_URL = "http://192.168.4.1/data"  # Replace with your ESP32's IP

# Initialize EasyOCR reader
reader = easyocr.Reader(['en'])

# Initialize drawing canvas
canvas_width, canvas_height = 800, 400
canvas = np.ones((canvas_height, canvas_width), dtype=np.uint8) * 255
recognized_texts = []  # Buffer to store recognized words

# Variables to track motion
prev_x, prev_y = canvas_width // 2, canvas_height // 2  # Start from center

def draw_with_imu(x, y):
    global prev_x, prev_y, canvas

    # Convert IMU acceleration values into screen coordinates
    new_x = int(prev_x + x)
    new_y = int(prev_y - y)  # Invert Y for correct direction

    # Keep the movement within canvas boundaries
    new_x = max(0, min(new_x, canvas_width - 1))
    new_y = max(0, min(new_y, canvas_height - 1))

    # Draw the movement
    cv2.line(canvas, (prev_x, prev_y), (new_x, new_y), (0, 0, 0), thickness=5)

    prev_x, prev_y = new_x, new_y

# Recognize text and save to file
def recognize_handwriting():
    global recognized_texts

    # Convert to grayscale and invert colors
    gray = cv2.bitwise_not(canvas)
    cv2.imwrite("temp.png", gray)  # Save the image for OCR

    # Use EasyOCR to recognize handwriting
    result = reader.readtext("temp.png")

    if result:
        words = " ".join([res[1] for res in result])
        recognized_texts.append(words)

# Create window
cv2.namedWindow("Handwriting Pad")

try:
    while True:
        response = requests.get(ESP32_URL)
        if response.status_code == 200:
            imu_data = response.text.strip()
            x, y = map(float, imu_data.split(","))  # Parse acceleration values
            draw_with_imu(x, y)  # Draw using IMU movement
        else:
            print("Error fetching data from ESP32")

        cv2.imshow("Handwriting Pad", canvas)

        # Display recognized text dynamically
        text_display = np.ones((100, canvas_width), dtype=np.uint8) * 255
        cv2.putText(text_display, f"Recognized: {' '.join(recognized_texts)}", (50, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)
        cv2.imshow("Recognized Text", text_display)

        key = cv2.waitKey(1) & 0xFF

        if key == ord('s'):  # Press 's' to process handwriting
            recognize_handwriting()

        elif key == ord('c'):  # Press 'c' to clear canvas
            canvas[:] = 255

        elif key == ord('q'):  # Press 'q' to quit
            break
except KeyboardInterrupt:
    print("Stopping data collection")

cv2.destroyAllWindows()
